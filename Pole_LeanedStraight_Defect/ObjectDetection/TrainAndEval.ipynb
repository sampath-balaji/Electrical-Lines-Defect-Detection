{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9f2f19-c464-4e53-bcb6-4c200ffb21ed",
   "metadata": {},
   "source": [
    "# Train and Validate the YOLOv12 Model\n",
    "\n",
    "This cell initiates the training and validation process using the YOLOv12 model on the prepared dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d603c-2dbd-488f-972a-6715f24e2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def train_model(model_path, data_yaml, device='cuda'):\n",
    "    \"\"\"\n",
    "    Trains a YOLO model on a given dataset.\n",
    "    \"\"\"\n",
    "    model = YOLO(model_path)\n",
    "    model.train(\n",
    "        data=data_yaml,\n",
    "        batch=16,\n",
    "        imgsz=640,\n",
    "        patience=0,      # Enable early stopping with some patience\n",
    "        epochs=200,\n",
    "        device=device,\n",
    "        half=True,\n",
    "        workers=0,\n",
    "        optimizer='auto'\n",
    "    )\n",
    "    print(\"âœ… Training complete.\")\n",
    "\n",
    "    val_metrics = model.val(split='val')\n",
    "    test_metrics = model.val(split='test')\n",
    "\n",
    "    print(\"ðŸ“Š Validation metrics:\", val_metrics)\n",
    "    print(\"ðŸ“Š Test metrics:\", test_metrics)\n",
    "\n",
    "# === CONFIG ===\n",
    "dataset_dir = \"/home/line_quality/line_quality/ElectricPoles_StraightLeaned-Defects\"\n",
    "data_yaml = os.path.join(dataset_dir, \"data.yaml\")\n",
    "train_model('yolo12m.pt', data_yaml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9197eb-39f6-4630-a63a-3b0a91d929e5",
   "metadata": {},
   "source": [
    "# Evaluation Utility Function\n",
    "\n",
    "This cell defines a utility function to evaluate the YOLOv12m model on the validation and test dataset, calculating metrics such as mAP, precision, recall and image level classification accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3293ba9-c226-4797-bcfd-707b4785ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "def evaluate_model(model_path, split, dataset_dir, output_dir, confidence_threshold=0.35):\n",
    "    \"\"\"\n",
    "    Evaluates the trained YOLO model at image-level classification\n",
    "    for the given dataset split ('val' or 'test').\n",
    "    \"\"\"\n",
    "    class_names = {0: \"Leaned_Pole\", 1: \"Straight_Pole\"}\n",
    "    image_dir = os.path.join(dataset_dir, split, \"images\")\n",
    "    gt_path = os.path.join(dataset_dir, split, \"labels\")\n",
    "    project_name = f'predict_{split}'\n",
    "    pred_path = os.path.join(output_dir, project_name, 'labels')\n",
    "\n",
    "    # Load model and run inference\n",
    "    model = YOLO(model_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    model.predict(\n",
    "        source=image_dir,\n",
    "        save=True,\n",
    "        save_txt=True,\n",
    "        save_conf=True,\n",
    "        project=output_dir,\n",
    "        name=project_name,\n",
    "        conf=confidence_threshold\n",
    "    )\n",
    "    print(f\"âœ… Inference complete for '{split}' set. Predictions saved to: {os.path.join(output_dir, project_name)}\")\n",
    "\n",
    "    # Evaluate predictions\n",
    "    results_data = {0: {\"gt\": [], \"pred\": [], \"fp_files\": [], \"fn_files\": []},\n",
    "                    1: {\"gt\": [], \"pred\": [], \"fp_files\": [], \"fn_files\": []}}\n",
    "\n",
    "    gt_files = [f for f in os.listdir(gt_path) if f.endswith(\".txt\")]\n",
    "\n",
    "    for file in gt_files:\n",
    "        gt_file = os.path.join(gt_path, file)\n",
    "        pred_file = os.path.join(pred_path, file)\n",
    "\n",
    "        with open(gt_file, \"r\") as f:\n",
    "            gt_classes = set(line.strip().split()[0] for line in f.readlines())\n",
    "\n",
    "        pred_classes = set()\n",
    "        if os.path.exists(pred_file):\n",
    "            with open(pred_file, \"r\") as f:\n",
    "                for line in f.readlines():\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) >= 6:\n",
    "                        class_id, conf = parts[0], float(parts[5])\n",
    "                        if conf >= confidence_threshold:\n",
    "                            pred_classes.add(class_id)\n",
    "\n",
    "        for class_id in class_names:\n",
    "            class_str = str(class_id)\n",
    "            gt_present = 1 if class_str in gt_classes else 0\n",
    "            pred_present = 1 if class_str in pred_classes else 0\n",
    "\n",
    "            results_data[class_id][\"gt\"].append(gt_present)\n",
    "            results_data[class_id][\"pred\"].append(pred_present)\n",
    "\n",
    "            if gt_present != pred_present:\n",
    "                (results_data[class_id][\"fp_files\"]\n",
    "                 if pred_present else results_data[class_id][\"fn_files\"]).append(file)\n",
    "\n",
    "    # Print classification metrics\n",
    "    for class_id, class_name in class_names.items():\n",
    "        y_true = results_data[class_id][\"gt\"]\n",
    "        y_pred = results_data[class_id][\"pred\"]\n",
    "\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        print(f\"\\nðŸ“Š {class_name} â€” {split.upper()} Set\")\n",
    "        print(f\"Accuracy:  {acc:.2%}\")\n",
    "        print(f\"Precision: {prec:.2%}\")\n",
    "        print(f\"Recall:    {rec:.2%}\")\n",
    "        print(f\"F1 Score:  {f1:.2%}\")\n",
    "        print(f\"Confusion Matrix [TN FP; FN TP]:\\n{cm}\")\n",
    "        for f in results_data[class_id][\"fp_files\"]:\n",
    "            print(f\"  FP: {f}\")\n",
    "        \n",
    "        print(f\"False Negatives ({len(results_data[class_id]['fn_files'])}):\")\n",
    "        for f in results_data[class_id][\"fn_files\"]:\n",
    "            print(f\"  FN: {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d4d3b-35c0-4bdd-9733-4b90895ba69f",
   "metadata": {},
   "source": [
    "# Run Evaluations on Val and Test Sets\n",
    "\n",
    "This cell runs the evaluation utility function on both the validation and test datasets using the trained YOLOv12 model. It prints performance metrics such as mAP, precision, and recall, and image level classification accuracy for each dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63355bbe-9f64-4be3-a89f-0b5e9d27a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"/home/line_quality/line_quality/ElectricPoles_StraightLeaned-Defects\"\n",
    "output_dir = \"/home/line_quality/line_quality/testing/predictions\"\n",
    "model_path = \"/home/line_quality/line_quality/testing/runs/detect/train5/weights/best.pt\"\n",
    "\n",
    "evaluate_model(model_path=model_path, split='valid', dataset_dir=dataset_dir, output_dir=output_dir)\n",
    "evaluate_model(model_path=model_path, split='test', dataset_dir=dataset_dir, output_dir=output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
